{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42253032-3183-49cc-b3f0-a1ab1f97763b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T02:21:29.729393Z",
     "iopub.status.busy": "2025-03-10T02:21:29.729032Z",
     "iopub.status.idle": "2025-03-10T02:22:00.647648Z",
     "shell.execute_reply": "2025-03-10T02:22:00.646006Z",
     "shell.execute_reply.started": "2025-03-10T02:21:29.729368Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"../datasets/net/train.csv\")\n",
    "train = pd.concat(\n",
    "    [\n",
    "        train.select_dtypes(\"int64\").astype(\"int32\"),\n",
    "        train.select_dtypes(\"float64\").astype(\"float32\"),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7858204b-5a5e-4341-a673-fb6365e73b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T02:22:00.649131Z",
     "iopub.status.busy": "2025-03-10T02:22:00.648639Z",
     "iopub.status.idle": "2025-03-10T02:22:00.655831Z",
     "shell.execute_reply": "2025-03-10T02:22:00.654574Z",
     "shell.execute_reply.started": "2025-03-10T02:22:00.649131Z"
    }
   },
   "outputs": [],
   "source": [
    "def margin_to_prob(margin):\n",
    "    return 1 / (1 + torch.exp(-margin * 0.25))\n",
    "\n",
    "\n",
    "def brier_score(probs, outcomes, chunk_size=10000):\n",
    "    total_score = 0\n",
    "    n_samples = probs.shape[0]\n",
    "\n",
    "    for i in range(0, n_samples, chunk_size):\n",
    "        end = min(i + chunk_size, n_samples)\n",
    "        chunk_score = torch.mean((probs[i:end] - outcomes[i:end]) ** 2)\n",
    "        total_score += chunk_score * (end - i)\n",
    "\n",
    "    return total_score / n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dcc34dfd-2e81-4f96-ba66-ab8b493224e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T02:22:00.658514Z",
     "iopub.status.busy": "2025-03-10T02:22:00.658079Z",
     "iopub.status.idle": "2025-03-10T02:22:14.008882Z",
     "shell.execute_reply": "2025-03-10T02:22:14.008089Z",
     "shell.execute_reply.started": "2025-03-10T02:22:00.658487Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "X = train.drop(columns=[\"Season\", \"DayNum\", \"TeamID_1\", \"TeamID_2\", \"Margin\"])\n",
    "X = X.values\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X = torch.as_tensor(X, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "y = train[\"Margin\"].values.reshape(-1, 1)\n",
    "y = StandardScaler().fit_transform(y)\n",
    "y = torch.as_tensor(y, dtype=torch.float32, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3cda441-8b73-436a-9440-75938aab5482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T02:22:14.015788Z",
     "iopub.status.busy": "2025-03-10T02:22:14.015623Z",
     "iopub.status.idle": "2025-03-10T02:24:13.860002Z",
     "shell.execute_reply": "2025-03-10T02:24:13.858876Z",
     "shell.execute_reply.started": "2025-03-10T02:22:14.015788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "  Epoch 0, Train Loss: 2.6716, Val Loss: 2.6357\n",
      "  Epoch 100, Train Loss: 2.2214, Val Loss: 2.1946\n",
      "  Epoch 200, Train Loss: 2.0061, Val Loss: 1.9846\n",
      "  Epoch 300, Train Loss: 1.8857, Val Loss: 1.8670\n",
      "  Epoch 400, Train Loss: 1.8022, Val Loss: 1.7851\n",
      "  Epoch 500, Train Loss: 1.7338, Val Loss: 1.7178\n",
      "  Epoch 600, Train Loss: 1.6734, Val Loss: 1.6583\n",
      "  Epoch 700, Train Loss: 1.6189, Val Loss: 1.6045\n",
      "  Epoch 800, Train Loss: 1.5693, Val Loss: 1.5556\n",
      "  Epoch 900, Train Loss: 1.5242, Val Loss: 1.5111\n",
      "Fold 1\n",
      "  Epoch 0, Train Loss: 1.6722, Val Loss: 1.6867\n",
      "  Epoch 100, Train Loss: 1.4943, Val Loss: 1.5099\n",
      "  Epoch 200, Train Loss: 1.3990, Val Loss: 1.4145\n",
      "  Epoch 300, Train Loss: 1.3292, Val Loss: 1.3448\n",
      "  Epoch 400, Train Loss: 1.2747, Val Loss: 1.2906\n",
      "  Epoch 500, Train Loss: 1.2308, Val Loss: 1.2468\n",
      "  Epoch 600, Train Loss: 1.1944, Val Loss: 1.2104\n",
      "  Epoch 700, Train Loss: 1.1634, Val Loss: 1.1795\n",
      "  Epoch 800, Train Loss: 1.1364, Val Loss: 1.1525\n",
      "  Epoch 900, Train Loss: 1.1125, Val Loss: 1.1286\n",
      "Fold 2\n",
      "  Epoch 0, Train Loss: 1.9467, Val Loss: 1.9514\n",
      "  Epoch 100, Train Loss: 1.7490, Val Loss: 1.7495\n",
      "  Epoch 200, Train Loss: 1.6657, Val Loss: 1.6647\n",
      "  Epoch 300, Train Loss: 1.5989, Val Loss: 1.5977\n",
      "  Epoch 400, Train Loss: 1.5389, Val Loss: 1.5378\n",
      "  Epoch 500, Train Loss: 1.4842, Val Loss: 1.4833\n",
      "  Epoch 600, Train Loss: 1.4342, Val Loss: 1.4336\n",
      "  Epoch 700, Train Loss: 1.3885, Val Loss: 1.3880\n",
      "  Epoch 800, Train Loss: 1.3463, Val Loss: 1.3461\n",
      "  Epoch 900, Train Loss: 1.3073, Val Loss: 1.3072\n",
      "Fold 3\n",
      "  Epoch 0, Train Loss: 2.4318, Val Loss: 2.4291\n",
      "  Epoch 100, Train Loss: 2.1310, Val Loss: 2.1242\n",
      "  Epoch 200, Train Loss: 1.9765, Val Loss: 1.9674\n",
      "  Epoch 300, Train Loss: 1.8782, Val Loss: 1.8679\n",
      "  Epoch 400, Train Loss: 1.8010, Val Loss: 1.7901\n",
      "  Epoch 500, Train Loss: 1.7342, Val Loss: 1.7231\n",
      "  Epoch 600, Train Loss: 1.6743, Val Loss: 1.6632\n",
      "  Epoch 700, Train Loss: 1.6198, Val Loss: 1.6088\n",
      "  Epoch 800, Train Loss: 1.5698, Val Loss: 1.5590\n",
      "  Epoch 900, Train Loss: 1.5237, Val Loss: 1.5131\n",
      "Fold 4\n",
      "  Epoch 0, Train Loss: 1.8218, Val Loss: 1.8387\n",
      "  Epoch 100, Train Loss: 1.6447, Val Loss: 1.6623\n",
      "  Epoch 200, Train Loss: 1.5311, Val Loss: 1.5489\n",
      "  Epoch 300, Train Loss: 1.4423, Val Loss: 1.4605\n",
      "  Epoch 400, Train Loss: 1.3710, Val Loss: 1.3894\n",
      "  Epoch 500, Train Loss: 1.3127, Val Loss: 1.3315\n",
      "  Epoch 600, Train Loss: 1.2643, Val Loss: 1.2833\n",
      "  Epoch 700, Train Loss: 1.2232, Val Loss: 1.2425\n",
      "  Epoch 800, Train Loss: 1.1877, Val Loss: 1.2071\n",
      "  Epoch 900, Train Loss: 1.1564, Val Loss: 1.1758\n",
      "Score: 0.2521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import torch.nn.functional as F\n",
    "\n",
    "hidden_size = 64\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "n_epochs = 1_000\n",
    "n_folds = 5\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "y_pred_oof = torch.zeros(y.shape[0], requires_grad=False, device=\"cuda\")\n",
    "\n",
    "for fold_n, (i_fold, i_oof) in enumerate(kfold.split(X)):\n",
    "    print(f\"Fold {fold_n}\")\n",
    "\n",
    "    weights1 = torch.randn(X.shape[1], hidden_size, device=\"cuda\") * 0.1\n",
    "    bias1 = torch.zeros(hidden_size, requires_grad=True, device=\"cuda\")\n",
    "    weights2 = torch.randn(hidden_size, 1, device=\"cuda\") * 0.1\n",
    "    bias2 = torch.zeros(1, requires_grad=True, device=\"cuda\")\n",
    "    optimizer = torch.optim.Adam([weights1, bias1, weights2, bias2], lr=0.001)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        y_pred = F.relu(X[i_fold] @ weights1 + bias1) @ weights2 + bias2\n",
    "        loss = loss_fn(y_pred, y[i_fold].view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_pred = F.relu(X[i_oof] @ weights1 + bias1) @ weights2 + bias2\n",
    "            val_loss = loss_fn(val_pred, y[i_oof].view(-1, 1))\n",
    "\n",
    "        if epoch % (n_epochs // 10) == 0:\n",
    "            print(\n",
    "                f\"  Epoch {epoch}, Train Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\"\n",
    "            )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_oof[i_oof] = (\n",
    "            F.relu(X[i_oof] @ weights1 + bias1) @ weights2 + bias2\n",
    "        ).flatten()\n",
    "\n",
    "score = brier_score(margin_to_prob(y_pred_oof), (y > 0).float())\n",
    "print(f\"Score: {score.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51902515-0142-4aeb-8b49-74d80577828c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d30621d-0136-4771-b51e-a094a54901d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
