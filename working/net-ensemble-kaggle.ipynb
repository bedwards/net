{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 91497,
     "databundleVersionId": 11320667,
     "sourceType": "competition"
    },
    {
     "sourceId": 11000041,
     "sourceType": "datasetVersion",
     "datasetId": 6847599
    }
   ],
   "dockerImageVersionId": 30919,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "df600378-9d40-4c40-b9a2-ae92ba890e1e",
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "IS_KAGGLE = bool(os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"))\n",
    "print(f\"running on kaggle: {IS_KAGGLE}\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-12T13:02:08.663481Z",
     "iopub.execute_input": "2025-03-12T13:02:08.663856Z",
     "iopub.status.idle": "2025-03-12T13:02:08.668859Z",
     "shell.execute_reply.started": "2025-03-12T13:02:08.663827Z",
     "shell.execute_reply": "2025-03-12T13:02:08.667802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "running on kaggle: True\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 80
  },
  {
   "id": "f699c97c-a50b-46f9-9efd-543ad473d460",
   "cell_type": "code",
   "source": "if not IS_KAGGLE:\n    !pip install --upgrade numpy pandas xgboost scikit-learn\n    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n    !pip install \\\n        --extra-index-url=https://pypi.nvidia.com \\\n        \"cudf-cu12==25.2.*\" \"dask-cudf-cu12==25.2.*\" \"cuml-cu12==25.2.*\" \\\n        \"cugraph-cu12==25.2.*\" \"nx-cugraph-cu12==25.2.*\" \"cuspatial-cu12==25.2.*\" \\\n        \"cuproj-cu12==25.2.*\" \"cuxfilter-cu12==25.2.*\" \"cucim-cu12==25.2.*\" \\\n        \"pylibraft-cu12==25.2.*\" \"raft-dask-cu12==25.2.*\" \"cuvs-cu12==25.2.*\" \\\n        \"nx-cugraph-cu12==25.2.*\"\n\n!pip install gputil",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-12T13:02:08.680872Z",
     "iopub.execute_input": "2025-03-12T13:02:08.681187Z",
     "iopub.status.idle": "2025-03-12T13:02:12.151145Z",
     "shell.execute_reply.started": "2025-03-12T13:02:08.681163Z",
     "shell.execute_reply": "2025-03-12T13:02:12.149894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: gputil in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 81
  },
  {
   "id": "7c831638-c357-474c-9913-326593f9d1d9",
   "cell_type": "code",
   "source": "import warnings\n\nwarnings.simplefilter(\"ignore\")\n\nimport json\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport torch\nimport torch.nn.functional as F\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nimport cudf\nimport GPUtil\nimport joblib\n\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    raise\n\ndatasets_dir = \"../input\" if IS_KAGGLE else \"../datasets\"\nkfold = KFold(shuffle=True, random_state=42)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T13:02:12.152988Z",
     "iopub.execute_input": "2025-03-12T13:02:12.153323Z",
     "iopub.status.idle": "2025-03-12T13:02:12.159794Z",
     "shell.execute_reply.started": "2025-03-12T13:02:12.153294Z",
     "shell.execute_reply": "2025-03-12T13:02:12.159025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": 82
  },
  {
   "id": "33aa42d7-39e8-43f8-9a3f-e46157420e4b",
   "cell_type": "code",
   "source": "fn = \"train_poss.csv\"\nprint(f\"reading {fn}\")\ntrain = pd.read_csv(f\"{datasets_dir}/net-dataset/{fn}\")\n\ntrain = pd.concat(\n    [\n        train.select_dtypes(\"int64\").astype(\"int32\"),\n        train.select_dtypes(\"float64\").astype(\"float32\"),\n    ],\n    axis=1,\n)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T13:02:12.161469Z",
     "iopub.execute_input": "2025-03-12T13:02:12.161694Z",
     "iopub.status.idle": "2025-03-12T13:02:15.487541Z",
     "shell.execute_reply.started": "2025-03-12T13:02:12.161673Z",
     "shell.execute_reply": "2025-03-12T13:02:15.486776Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "reading train_poss.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 83
  },
  {
   "id": "ec4dbca3-c555-4996-ad2c-c706c3428610",
   "cell_type": "code",
   "source": [
    "print(\"train\")\n",
    "int_cols = train.select_dtypes(\"int32\").columns.to_list()\n",
    "print(f\"{len(int_cols):>3} {int_cols}\")\n",
    "float_cols = train.select_dtypes(\"float32\").columns.to_list()\n",
    "o_cols = [c for c in float_cols if c.split(\"_\")[2] == \"o\"]\n",
    "print(f\"{len(o_cols):>3} {o_cols[:3]} ... {o_cols[-3:]}\")\n",
    "d_cols = [c for c in float_cols if c.split(\"_\")[2] == \"d\"]\n",
    "print(f\"{len(d_cols):>3} {d_cols[:3]} ... {d_cols[-3:]}\")\n",
    "sos_o_cols = [c for c in float_cols if c.split(\"_\")[3] == \"o\"]\n",
    "print(f\"{len(sos_o_cols):>3} {sos_o_cols[:3]} ... {sos_o_cols[-3:]}\")\n",
    "sos_d_cols = [c for c in float_cols if c.split(\"_\")[3] == \"d\"]\n",
    "print(f\"{len(sos_d_cols):>3} {sos_d_cols[:3]} ... {sos_d_cols[-3:]}\")\n",
    "print(\"---\")\n",
    "print(\n",
    "    f\"{train.shape[1]} {len(int_cols) + len(o_cols) + len(d_cols) + len(sos_o_cols) + len(sos_d_cols)}\"\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-12T13:02:15.488886Z",
     "iopub.execute_input": "2025-03-12T13:02:15.489139Z",
     "iopub.status.idle": "2025-03-12T13:02:15.518437Z",
     "shell.execute_reply.started": "2025-03-12T13:02:15.489110Z",
     "shell.execute_reply": "2025-03-12T13:02:15.517508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "train\n  5 ['Season', 'DayNum', 'TeamID_1', 'TeamID_2', 'Margin']\n 28 ['Score_poss_o_1', 'FGM_poss_o_1', 'FGA_poss_o_1'] ... ['Stl_poss_o_2', 'Blk_poss_o_2', 'PF_poss_o_2']\n 28 ['Score_poss_d_1', 'FGM_poss_d_1', 'FGA_poss_d_1'] ... ['Stl_poss_d_2', 'Blk_poss_d_2', 'PF_poss_d_2']\n 28 ['sos_Score_poss_o_1', 'sos_FGM_poss_o_1', 'sos_FGA_poss_o_1'] ... ['sos_Stl_poss_o_2', 'sos_Blk_poss_o_2', 'sos_PF_poss_o_2']\n 28 ['sos_Score_poss_d_1', 'sos_FGM_poss_d_1', 'sos_FGA_poss_d_1'] ... ['sos_Stl_poss_d_2', 'sos_Blk_poss_d_2', 'sos_PF_poss_d_2']\n---\n117 117\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 84
  },
  {
   "id": "d2927d4b-8b36-4c2b-a795-25cf31f89f93",
   "cell_type": "code",
   "source": "print(f\"train: {str(train.shape):>23}\")\n\nX_df = train.drop(columns=[\"Season\", \"DayNum\", \"TeamID_1\", \"TeamID_2\", \"Margin\"])\nprint(f\"X_df: {str(X_df.shape):>24}\")\n\ny_s = train[\"Margin\"]\nprint(f\"y_s: {str(y_s.shape):>21}\")\nscaler_y = StandardScaler()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T13:02:15.519320Z",
     "iopub.execute_input": "2025-03-12T13:02:15.519569Z",
     "iopub.status.idle": "2025-03-12T13:02:15.546396Z",
     "shell.execute_reply.started": "2025-03-12T13:02:15.519547Z",
     "shell.execute_reply": "2025-03-12T13:02:15.545570Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "train:           (202033, 117)\nX_df:            (202033, 112)\ny_s:             (202033,)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 85
  },
  {
   "id": "a4b9f99f-7e01-41e1-b8d8-94be5d26efa1",
   "cell_type": "code",
   "source": "def brier_score(y_pred_oof):\n    win_prob_pred_oof = 1 / (1 + np.exp(-y_pred_oof * 0.1))\n    team_1_won = (y_s > 0).astype(\"int32\")\n    return np.mean((win_prob_pred_oof - team_1_won) ** 2)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T13:02:15.547411Z",
     "iopub.execute_input": "2025-03-12T13:02:15.547797Z",
     "iopub.status.idle": "2025-03-12T13:02:15.552313Z",
     "shell.execute_reply.started": "2025-03-12T13:02:15.547757Z",
     "shell.execute_reply": "2025-03-12T13:02:15.551408Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": 86
  },
  {
   "id": "7742f9cc-5a0a-4cea-a06e-f12e18e03a32",
   "cell_type": "code",
   "source": [
    "print(f\"xgboost\")\n",
    "xgb_models = []\n",
    "y_pred_oof = np.zeros(y_s.shape[0])\n",
    "\n",
    "for fold_n, (i_fold, i_oof) in enumerate(kfold.split(X_df.index), 1):\n",
    "    print(f\"  fold {fold_n}\")\n",
    "    m = xgb.XGBRegressor(\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "        max_depth=3,\n",
    "        colsample_bytree=0.5,\n",
    "        subsample=0.8,\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.02,\n",
    "        min_child_weight=80,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    X_fold = cudf.DataFrame.from_pandas(X_df.iloc[i_fold])\n",
    "    y_fold = cudf.Series(y_s.iloc[i_fold])\n",
    "    X_oof = cudf.DataFrame.from_pandas(X_df.iloc[i_oof])\n",
    "    y_oof = cudf.Series(y_s.iloc[i_oof])\n",
    "\n",
    "    m.fit(\n",
    "        X_fold,\n",
    "        y_fold,\n",
    "        verbose=500,\n",
    "        eval_set=[(X_fold, y_fold), (X_oof, y_oof)],\n",
    "    )\n",
    "\n",
    "    xgb_models.append(m)\n",
    "    y_pred_oof[i_oof] = m.predict(X_oof)\n",
    "    GPUtil.showUtilization()\n",
    "    print()\n",
    "\n",
    "score = brier_score(y_pred_oof)\n",
    "print(f\"xgboost score: {score:.4f}\")\n",
    "\n",
    "for fold_n, m in enumerate(xgb_models, 1):\n",
    "    fn = f\"xgb_{f'{score:.4f}'[2:6]}_{fold_n}.zip\"\n",
    "    joblib.dump(m, fn, compress=3)\n",
    "    print(f\"wrote {fn}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T13:17:21.950851Z",
     "iopub.execute_input": "2025-03-12T13:17:21.951154Z",
     "iopub.status.idle": "2025-03-12T13:18:15.635502Z",
     "shell.execute_reply.started": "2025-03-12T13:17:21.951131Z",
     "shell.execute_reply": "2025-03-12T13:18:15.634640Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "xgboost\n  fold 1\n[0]\tvalidation_0-rmse:16.41412\tvalidation_1-rmse:16.49274\n[500]\tvalidation_0-rmse:11.23284\tvalidation_1-rmse:11.35894\n[1000]\tvalidation_0-rmse:10.97224\tvalidation_1-rmse:11.13901\n[1500]\tvalidation_0-rmse:10.89068\tvalidation_1-rmse:11.09109\n[1999]\tvalidation_0-rmse:10.83845\tvalidation_1-rmse:11.07211\n| ID | GPU | MEM |\n------------------\n|  0 | 51% |  4% |\n|  1 |  0% |  0% |\n\n  fold 2\n[0]\tvalidation_0-rmse:16.41678\tvalidation_1-rmse:16.44453\n[500]\tvalidation_0-rmse:11.24746\tvalidation_1-rmse:11.27648\n[1000]\tvalidation_0-rmse:10.99009\tvalidation_1-rmse:11.05728\n[1500]\tvalidation_0-rmse:10.90663\tvalidation_1-rmse:11.01255\n[1999]\tvalidation_0-rmse:10.85455\tvalidation_1-rmse:10.99577\n| ID | GPU | MEM |\n------------------\n|  0 | 43% |  4% |\n|  1 |  0% |  0% |\n\n  fold 3\n[0]\tvalidation_0-rmse:16.43755\tvalidation_1-rmse:16.40973\n[500]\tvalidation_0-rmse:11.23273\tvalidation_1-rmse:11.34793\n[1000]\tvalidation_0-rmse:10.97384\tvalidation_1-rmse:11.12728\n[1500]\tvalidation_0-rmse:10.89302\tvalidation_1-rmse:11.08192\n[1999]\tvalidation_0-rmse:10.84202\tvalidation_1-rmse:11.06395\n| ID | GPU | MEM |\n------------------\n|  0 | 52% |  4% |\n|  1 |  0% |  0% |\n\n  fold 4\n[0]\tvalidation_0-rmse:16.44885\tvalidation_1-rmse:16.36198\n[500]\tvalidation_0-rmse:11.24018\tvalidation_1-rmse:11.31309\n[1000]\tvalidation_0-rmse:10.98027\tvalidation_1-rmse:11.10693\n[1500]\tvalidation_0-rmse:10.89967\tvalidation_1-rmse:11.06103\n[1999]\tvalidation_0-rmse:10.84942\tvalidation_1-rmse:11.04161\n| ID | GPU | MEM |\n------------------\n|  0 | 40% |  4% |\n|  1 |  0% |  0% |\n\n  fold 5\n[0]\tvalidation_0-rmse:16.42735\tvalidation_1-rmse:16.43855\n[500]\tvalidation_0-rmse:11.24305\tvalidation_1-rmse:11.32131\n[1000]\tvalidation_0-rmse:10.98315\tvalidation_1-rmse:11.09827\n[1500]\tvalidation_0-rmse:10.90162\tvalidation_1-rmse:11.05145\n[1999]\tvalidation_0-rmse:10.84913\tvalidation_1-rmse:11.03351\n| ID | GPU | MEM |\n------------------\n|  0 | 38% |  4% |\n|  1 |  0% |  0% |\n\nxgboost score: 0.1660\nwrote xgb_1660_1.zip\nwrote xgb_1660_2.zip\nwrote xgb_1660_3.zip\nwrote xgb_1660_4.zip\nwrote xgb_1660_5.zip\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 90
  },
  {
   "id": "5da53c98-c616-4e83-9e0d-0d732e0eeb59",
   "cell_type": "code",
   "source": [
    "print(\"torch\")\n",
    "\n",
    "X = torch.as_tensor(\n",
    "    StandardScaler().fit_transform(X_df.values),\n",
    "    dtype=torch.float32,\n",
    "    device=device,\n",
    ")\n",
    "print(f\"X:    {X.shape}\")\n",
    "\n",
    "y = torch.tensor(\n",
    "    scaler_y.fit_transform(train[[\"Margin\"]]).flatten(),\n",
    "    dtype=torch.float32,\n",
    "    device=device,\n",
    ")\n",
    "print(f\"y:    {y.shape}\")\n",
    "\n",
    "\n",
    "def weight(*size):\n",
    "    return torch.nn.Parameter(0.1 * torch.randn(*size, device=device))\n",
    "\n",
    "\n",
    "def bias(*size):\n",
    "    return torch.nn.Parameter(torch.zeros(*size, device=device))\n",
    "\n",
    "\n",
    "mse_ = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "def mse(y_pred_epoch, i):\n",
    "    return loss_fn(y_pred_epoch, y[i].view(-1, 1))\n",
    "\n",
    "\n",
    "def aslist(param):\n",
    "    return param.cpu().detach().numpy().tolist()\n",
    "\n",
    "\n",
    "def aspy(m):\n",
    "    return {\n",
    "        \"w\": [aslist(w) for w in m[\"w\"]],\n",
    "        \"b\": [aslist(b) for b in m[\"b\"]],\n",
    "    }\n",
    "\n",
    "\n",
    "n_epochs = 1_000\n",
    "hidden_size = 64\n",
    "torch_models = []\n",
    "\n",
    "y_pred_oof = torch.zeros(\n",
    "    y.shape[0],\n",
    "    dtype=torch.float32,\n",
    "    requires_grad=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "for fold_n, (i_fold, i_oof) in enumerate(kfold.split(X_df.index), 1):\n",
    "    print(f\"  fold {fold_n}\")\n",
    "\n",
    "    m = {\n",
    "        \"w\": [\n",
    "            weight(X_df.shape[1], hidden_size),\n",
    "            weight(hidden_size, 1),\n",
    "        ],\n",
    "        \"b\": [\n",
    "            bias(hidden_size),\n",
    "            bias(1),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    optimizer = torch.optim.Adam(m[\"w\"] + m[\"b\"], weight_decay=1e-4)\n",
    "\n",
    "    def forward(i):\n",
    "        return (\n",
    "            F.leaky_relu(X[i] @ m[\"w\"][0] + m[\"b\"][0], negative_slope=0.1) @ m[\"w\"][1]\n",
    "            + m[\"b\"][1]\n",
    "        )\n",
    "\n",
    "    for epoch_n in range(1, n_epochs + 1):\n",
    "        y_pred_epoch_fold = forward(i_fold)\n",
    "        loss_fold_epoch = mse(y_pred_epoch_fold, i_fold)\n",
    "        optimizer.zero_grad()\n",
    "        loss_fold_epoch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred_epoch_oof = forward(i_oof)\n",
    "            loss_oof_epoch = mse(y_pred_epoch_oof, i_oof)\n",
    "\n",
    "        if epoch_n > (n_epochs - 3):\n",
    "            print(\n",
    "                f\"    epoch {epoch_n:>6}: \"\n",
    "                f\"fold={loss_fold_epoch.item():.4f} \"\n",
    "                f\"oof={loss_oof_epoch.item():.4f}\"\n",
    "            )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_oof[i_oof] = forward(i_oof).flatten()\n",
    "\n",
    "    GPUtil.showUtilization()\n",
    "\n",
    "    torch_models.append(aspy(m))\n",
    "\n",
    "    print()\n",
    "\n",
    "y_pred_oof = scaler_y.inverse_transform(\n",
    "    y_pred_oof.cpu().numpy().reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "score = brier_score(y_pred_oof)\n",
    "print(f\"torch score:   {score:.4f}\")\n",
    "\n",
    "for fold_n, m in enumerate(torch_models, 1):\n",
    "    fn = f\"nn_{f'{score:.4f}'[2:6]}_{fold_n}.json\"\n",
    "    with open(fn, \"w\") as f:\n",
    "        json.dump(m, f)\n",
    "    print(f\"wrote {fn}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T13:23:35.852851Z",
     "iopub.execute_input": "2025-03-12T13:23:35.853187Z",
     "iopub.status.idle": "2025-03-12T13:24:13.487557Z",
     "shell.execute_reply.started": "2025-03-12T13:23:35.853166Z",
     "shell.execute_reply": "2025-03-12T13:24:13.486631Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "torch\nX:    torch.Size([202033, 112])\ny:    torch.Size([202033])\n  fold 1\n    epoch    998: fold=0.4307 oof=0.4456\n    epoch    999: fold=0.4307 oof=0.4457\n    epoch   1000: fold=0.4307 oof=0.4457\n| ID | GPU | MEM |\n------------------\n|  0 | 87% |  4% |\n|  1 |  0% |  0% |\n\n  fold 2\n    epoch    998: fold=0.4336 oof=0.4400\n    epoch    999: fold=0.4336 oof=0.4400\n    epoch   1000: fold=0.4336 oof=0.4400\n| ID | GPU | MEM |\n------------------\n|  0 | 88% |  4% |\n|  1 |  0% |  0% |\n\n  fold 3\n    epoch    998: fold=0.4317 oof=0.4445\n    epoch    999: fold=0.4317 oof=0.4446\n    epoch   1000: fold=0.4317 oof=0.4445\n| ID | GPU | MEM |\n------------------\n|  0 | 80% |  4% |\n|  1 |  0% |  0% |\n\n  fold 4\n    epoch    998: fold=0.4333 oof=0.4429\n    epoch    999: fold=0.4333 oof=0.4430\n    epoch   1000: fold=0.4332 oof=0.4429\n| ID | GPU | MEM |\n------------------\n|  0 | 87% |  4% |\n|  1 |  0% |  0% |\n\n  fold 5\n    epoch    998: fold=0.4318 oof=0.4433\n    epoch    999: fold=0.4318 oof=0.4433\n    epoch   1000: fold=0.4318 oof=0.4433\n| ID | GPU | MEM |\n------------------\n|  0 | 88% |  4% |\n|  1 |  0% |  0% |\n\ntorch score:   0.1649\nwrote nn_1649_1.json\nwrote nn_1649_2.json\nwrote nn_1649_3.json\nwrote nn_1649_4.json\nwrote nn_1649_5.json\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 91
  },
  {
   "id": "b4b97a9a-a1e9-4715-af23-213948d42de6",
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}