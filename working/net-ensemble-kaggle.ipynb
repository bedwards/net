{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 91497,
     "databundleVersionId": 11320667,
     "sourceType": "competition"
    },
    {
     "sourceId": 11000041,
     "sourceType": "datasetVersion",
     "datasetId": 6847599
    }
   ],
   "dockerImageVersionId": 30919,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "df600378-9d40-4c40-b9a2-ae92ba890e1e",
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "IS_KAGGLE = bool(os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"))\n",
    "print(f\"running on kaggle: {IS_KAGGLE}\")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-12T11:45:19.412505Z",
     "iopub.execute_input": "2025-03-12T11:45:19.412952Z",
     "iopub.status.idle": "2025-03-12T11:45:19.420624Z",
     "shell.execute_reply.started": "2025-03-12T11:45:19.412919Z",
     "shell.execute_reply": "2025-03-12T11:45:19.419688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "running on kaggle: True\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 68
  },
  {
   "id": "f699c97c-a50b-46f9-9efd-543ad473d460",
   "cell_type": "code",
   "source": "if not IS_KAGGLE:\n    !pip install --upgrade numpy pandas xgboost scikit-learn\n    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n    !pip install \\\n        --extra-index-url=https://pypi.nvidia.com \\\n        \"cudf-cu12==25.2.*\" \"dask-cudf-cu12==25.2.*\" \"cuml-cu12==25.2.*\" \\\n        \"cugraph-cu12==25.2.*\" \"nx-cugraph-cu12==25.2.*\" \"cuspatial-cu12==25.2.*\" \\\n        \"cuproj-cu12==25.2.*\" \"cuxfilter-cu12==25.2.*\" \"cucim-cu12==25.2.*\" \\\n        \"pylibraft-cu12==25.2.*\" \"raft-dask-cu12==25.2.*\" \"cuvs-cu12==25.2.*\" \\\n        \"nx-cugraph-cu12==25.2.*\"\n\n!pip install gputil",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-12T11:45:19.421884Z",
     "iopub.execute_input": "2025-03-12T11:45:19.422186Z",
     "iopub.status.idle": "2025-03-12T11:45:22.769602Z",
     "shell.execute_reply.started": "2025-03-12T11:45:19.422153Z",
     "shell.execute_reply": "2025-03-12T11:45:22.768632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: gputil in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 69
  },
  {
   "id": "7c831638-c357-474c-9913-326593f9d1d9",
   "cell_type": "code",
   "source": "import warnings\n\nwarnings.simplefilter(\"ignore\")\n\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport torch\nimport torch.nn.functional as F\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nimport cudf\nimport GPUtil\n\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    raise\n\ndatasets_dir = \"../input\" if IS_KAGGLE else \"../datasets\"\nkfold = KFold(shuffle=True, random_state=42)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T11:45:22.771779Z",
     "iopub.execute_input": "2025-03-12T11:45:22.772125Z",
     "iopub.status.idle": "2025-03-12T11:45:22.777845Z",
     "shell.execute_reply.started": "2025-03-12T11:45:22.772091Z",
     "shell.execute_reply": "2025-03-12T11:45:22.776987Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": 70
  },
  {
   "id": "33aa42d7-39e8-43f8-9a3f-e46157420e4b",
   "cell_type": "code",
   "source": "fn = \"train_poss.csv\"\nprint(f\"reading {fn}\")\ntrain = pd.read_csv(f\"{datasets_dir}/net-dataset/{fn}\")\n\ntrain = pd.concat(\n    [\n        train.select_dtypes(\"int64\").astype(\"int32\"),\n        train.select_dtypes(\"float64\").astype(\"float32\"),\n    ],\n    axis=1,\n)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T11:45:22.779223Z",
     "iopub.execute_input": "2025-03-12T11:45:22.779512Z",
     "iopub.status.idle": "2025-03-12T11:45:25.954242Z",
     "shell.execute_reply.started": "2025-03-12T11:45:22.779489Z",
     "shell.execute_reply": "2025-03-12T11:45:25.953317Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "reading train_poss.csv\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 71
  },
  {
   "id": "ec4dbca3-c555-4996-ad2c-c706c3428610",
   "cell_type": "code",
   "source": [
    "print(\"train\")\n",
    "int_cols = train.select_dtypes(\"int32\").columns.to_list()\n",
    "print(f\"{len(int_cols):>3} {int_cols}\")\n",
    "float_cols = train.select_dtypes(\"float32\").columns.to_list()\n",
    "o_cols = [c for c in float_cols if c.split(\"_\")[2] == \"o\"]\n",
    "print(f\"{len(o_cols):>3} {o_cols[:3]} ... {o_cols[-3:]}\")\n",
    "d_cols = [c for c in float_cols if c.split(\"_\")[2] == \"d\"]\n",
    "print(f\"{len(d_cols):>3} {d_cols[:3]} ... {d_cols[-3:]}\")\n",
    "sos_o_cols = [c for c in float_cols if c.split(\"_\")[3] == \"o\"]\n",
    "print(f\"{len(sos_o_cols):>3} {sos_o_cols[:3]} ... {sos_o_cols[-3:]}\")\n",
    "sos_d_cols = [c for c in float_cols if c.split(\"_\")[3] == \"d\"]\n",
    "print(f\"{len(sos_d_cols):>3} {sos_d_cols[:3]} ... {sos_d_cols[-3:]}\")\n",
    "print(\"---\")\n",
    "print(\n",
    "    f\"{train.shape[1]} {len(int_cols) + len(o_cols) + len(d_cols) + len(sos_o_cols) + len(sos_d_cols)}\"\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-03-12T11:45:25.955192Z",
     "iopub.execute_input": "2025-03-12T11:45:25.955577Z",
     "iopub.status.idle": "2025-03-12T11:45:25.985570Z",
     "shell.execute_reply.started": "2025-03-12T11:45:25.955539Z",
     "shell.execute_reply": "2025-03-12T11:45:25.984762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "train\n  5 ['Season', 'DayNum', 'TeamID_1', 'TeamID_2', 'Margin']\n 28 ['Score_poss_o_1', 'FGM_poss_o_1', 'FGA_poss_o_1'] ... ['Stl_poss_o_2', 'Blk_poss_o_2', 'PF_poss_o_2']\n 28 ['Score_poss_d_1', 'FGM_poss_d_1', 'FGA_poss_d_1'] ... ['Stl_poss_d_2', 'Blk_poss_d_2', 'PF_poss_d_2']\n 28 ['sos_Score_poss_o_1', 'sos_FGM_poss_o_1', 'sos_FGA_poss_o_1'] ... ['sos_Stl_poss_o_2', 'sos_Blk_poss_o_2', 'sos_PF_poss_o_2']\n 28 ['sos_Score_poss_d_1', 'sos_FGM_poss_d_1', 'sos_FGA_poss_d_1'] ... ['sos_Stl_poss_d_2', 'sos_Blk_poss_d_2', 'sos_PF_poss_d_2']\n---\n117 117\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 72
  },
  {
   "id": "d2927d4b-8b36-4c2b-a795-25cf31f89f93",
   "cell_type": "code",
   "source": "print(f\"train: {str(train.shape):>23}\")\n\nX_df = train.drop(columns=[\"Season\", \"DayNum\", \"TeamID_1\", \"TeamID_2\", \"Margin\"])\nprint(f\"X_df: {str(X_df.shape):>24}\")\n\ny_s = train[\"Margin\"]\nprint(f\"y_s: {str(y_s.shape):>21}\")\nscaler_y = StandardScaler()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T11:45:25.986503Z",
     "iopub.execute_input": "2025-03-12T11:45:25.986860Z",
     "iopub.status.idle": "2025-03-12T11:45:26.012966Z",
     "shell.execute_reply.started": "2025-03-12T11:45:25.986826Z",
     "shell.execute_reply": "2025-03-12T11:45:26.012111Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "train:           (202033, 117)\nX_df:            (202033, 112)\ny_s:             (202033,)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 73
  },
  {
   "id": "a4b9f99f-7e01-41e1-b8d8-94be5d26efa1",
   "cell_type": "code",
   "source": "def brier_score(y_pred_oof):\n    win_prob_pred_oof = 1 / (1 + np.exp(-y_pred_oof * 0.1))\n    team_1_won = (y_s > 0).astype(\"int32\")\n    return np.mean((win_prob_pred_oof - team_1_won) ** 2)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T11:45:26.015186Z",
     "iopub.execute_input": "2025-03-12T11:45:26.015441Z",
     "iopub.status.idle": "2025-03-12T11:45:26.019637Z",
     "shell.execute_reply.started": "2025-03-12T11:45:26.015420Z",
     "shell.execute_reply": "2025-03-12T11:45:26.018819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "execution_count": 74
  },
  {
   "id": "7742f9cc-5a0a-4cea-a06e-f12e18e03a32",
   "cell_type": "code",
   "source": [
    "print(f\"xgboost\")\n",
    "y_pred_oof = np.zeros(y_s.shape[0])\n",
    "\n",
    "for fold_n, (i_fold, i_oof) in enumerate(kfold.split(X_df.index), 1):\n",
    "    print(f\"  fold {fold_n}\")\n",
    "    m = xgb.XGBRegressor(\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "        max_depth=3,\n",
    "        colsample_bytree=0.5,\n",
    "        subsample=0.8,\n",
    "        n_estimators=2000,\n",
    "        learning_rate=0.02,\n",
    "        min_child_weight=80,\n",
    "        verbosity=1,\n",
    "    )\n",
    "\n",
    "    X_fold = cudf.DataFrame.from_pandas(X_df.iloc[i_fold])\n",
    "    y_fold = cudf.Series(y_s.iloc[i_fold])\n",
    "    X_oof = cudf.DataFrame.from_pandas(X_df.iloc[i_oof])\n",
    "    y_oof = cudf.Series(y_s.iloc[i_oof])\n",
    "\n",
    "    m.fit(\n",
    "        X_fold,\n",
    "        y_fold,\n",
    "        verbose=500,\n",
    "        eval_set=[(X_fold, y_fold), (X_oof, y_oof)],\n",
    "    )\n",
    "\n",
    "    y_pred_oof[i_oof] = m.predict(X_oof)\n",
    "    GPUtil.showUtilization()\n",
    "    print()\n",
    "\n",
    "score = brier_score(y_pred_oof)\n",
    "print(f\"xgboost score: {score:.4f}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T11:45:26.020672Z",
     "iopub.execute_input": "2025-03-12T11:45:26.020961Z",
     "iopub.status.idle": "2025-03-12T11:46:18.711006Z",
     "shell.execute_reply.started": "2025-03-12T11:45:26.020939Z",
     "shell.execute_reply": "2025-03-12T11:46:18.710082Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "xgboost\n  fold 1\n[0]\tvalidation_0-rmse:16.41412\tvalidation_1-rmse:16.49274\n[500]\tvalidation_0-rmse:11.23284\tvalidation_1-rmse:11.35894\n[1000]\tvalidation_0-rmse:10.97224\tvalidation_1-rmse:11.13901\n[1500]\tvalidation_0-rmse:10.89068\tvalidation_1-rmse:11.09109\n[1999]\tvalidation_0-rmse:10.83845\tvalidation_1-rmse:11.07211\n| ID | GPU | MEM |\n------------------\n|  0 | 11% |  4% |\n|  1 |  0% |  0% |\n\n  fold 2\n[0]\tvalidation_0-rmse:16.41678\tvalidation_1-rmse:16.44453\n[500]\tvalidation_0-rmse:11.24746\tvalidation_1-rmse:11.27648\n[1000]\tvalidation_0-rmse:10.99009\tvalidation_1-rmse:11.05728\n[1500]\tvalidation_0-rmse:10.90663\tvalidation_1-rmse:11.01255\n[1999]\tvalidation_0-rmse:10.85455\tvalidation_1-rmse:10.99577\n| ID | GPU | MEM |\n------------------\n|  0 | 24% |  4% |\n|  1 |  0% |  0% |\n\n  fold 3\n[0]\tvalidation_0-rmse:16.43755\tvalidation_1-rmse:16.40973\n[500]\tvalidation_0-rmse:11.23273\tvalidation_1-rmse:11.34793\n[1000]\tvalidation_0-rmse:10.97384\tvalidation_1-rmse:11.12728\n[1500]\tvalidation_0-rmse:10.89302\tvalidation_1-rmse:11.08192\n[1999]\tvalidation_0-rmse:10.84202\tvalidation_1-rmse:11.06395\n| ID | GPU | MEM |\n------------------\n|  0 | 20% |  4% |\n|  1 |  0% |  0% |\n\n  fold 4\n[0]\tvalidation_0-rmse:16.44885\tvalidation_1-rmse:16.36198\n[500]\tvalidation_0-rmse:11.24018\tvalidation_1-rmse:11.31309\n[1000]\tvalidation_0-rmse:10.98027\tvalidation_1-rmse:11.10693\n[1500]\tvalidation_0-rmse:10.89967\tvalidation_1-rmse:11.06103\n[1999]\tvalidation_0-rmse:10.84942\tvalidation_1-rmse:11.04161\n| ID | GPU | MEM |\n------------------\n|  0 | 23% |  4% |\n|  1 |  0% |  0% |\n\n  fold 5\n[0]\tvalidation_0-rmse:16.42735\tvalidation_1-rmse:16.43855\n[500]\tvalidation_0-rmse:11.24305\tvalidation_1-rmse:11.32131\n[1000]\tvalidation_0-rmse:10.98315\tvalidation_1-rmse:11.09827\n[1500]\tvalidation_0-rmse:10.90162\tvalidation_1-rmse:11.05145\n[1999]\tvalidation_0-rmse:10.84913\tvalidation_1-rmse:11.03351\n| ID | GPU | MEM |\n------------------\n|  0 | 50% |  4% |\n|  1 |  0% |  0% |\n\nxgboost score: 0.1660\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 75
  },
  {
   "id": "5da53c98-c616-4e83-9e0d-0d732e0eeb59",
   "cell_type": "code",
   "source": [
    "print(\"torch\")\n",
    "\n",
    "X = torch.as_tensor(\n",
    "    StandardScaler().fit_transform(X_df.values),\n",
    "    dtype=torch.float32,\n",
    "    device=device,\n",
    ")\n",
    "print(f\"X:    {X.shape}\")\n",
    "\n",
    "y = torch.tensor(\n",
    "    scaler_y.fit_transform(train[[\"Margin\"]]).flatten(),\n",
    "    dtype=torch.float32,\n",
    "    device=device,\n",
    ")\n",
    "print(f\"y:    {y.shape}\")\n",
    "\n",
    "n_epochs = 1_000\n",
    "hidden_size = 64\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "y_pred_oof = torch.zeros(\n",
    "    y.shape[0],\n",
    "    dtype=torch.float32,\n",
    "    requires_grad=False,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "for fold_n, (i_fold, i_oof) in enumerate(kfold.split(X_df.index), 1):\n",
    "    print(f\"  fold {fold_n}\")\n",
    "\n",
    "    weights1 = torch.nn.Parameter(\n",
    "        0.1 * torch.randn(X_df.shape[1], hidden_size, device=device)\n",
    "    )\n",
    "    bias1 = torch.nn.Parameter(torch.zeros(hidden_size, device=device))\n",
    "    weights2 = torch.nn.Parameter(0.1 * torch.randn(hidden_size, 1, device=device))\n",
    "    bias2 = torch.nn.Parameter(torch.zeros(1, device=device))\n",
    "    optimizer = torch.optim.Adam([weights1, bias1, weights2, bias2], weight_decay=1e-4)\n",
    "\n",
    "    for epoch_n in range(1, n_epochs + 1):\n",
    "        y_pred_fold_epoch = (\n",
    "            F.leaky_relu(X[i_fold] @ weights1 + bias1, negative_slope=0.1) @ weights2\n",
    "            + bias2\n",
    "        )\n",
    "        loss_fold_epoch = loss_fn(y_pred_fold_epoch, y[i_fold].view(-1, 1))\n",
    "        optimizer.zero_grad()\n",
    "        loss_fold_epoch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred_oof_epoch = (\n",
    "                F.leaky_relu(X[i_oof] @ weights1 + bias1, negative_slope=0.1) @ weights2\n",
    "                + bias2\n",
    "            )\n",
    "            loss_oof_epoch = loss_fn(y_pred_oof_epoch, y[i_oof].view(-1, 1))\n",
    "\n",
    "        if epoch_n > (n_epochs - 3):\n",
    "            print(\n",
    "                f\"    epoch {epoch_n:>6}: \"\n",
    "                f\"fold={loss_fold_epoch.item():.4f} \"\n",
    "                f\"oof={loss_oof_epoch.item():.4f}\"\n",
    "            )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_pred_oof[i_oof] = (\n",
    "            F.leaky_relu(X[i_oof] @ weights1 + bias1, negative_slope=0.1) @ weights2\n",
    "            + bias2\n",
    "        ).flatten()\n",
    "\n",
    "    GPUtil.showUtilization()\n",
    "    print()\n",
    "\n",
    "y_pred_oof = scaler_y.inverse_transform(\n",
    "    y_pred_oof.cpu().numpy().reshape(-1, 1)\n",
    ").flatten()\n",
    "\n",
    "score = brier_score(y_pred_oof)\n",
    "print(f\"torch score:   {score:.4f}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-03-12T11:46:18.711931Z",
     "iopub.execute_input": "2025-03-12T11:46:18.712244Z",
     "iopub.status.idle": "2025-03-12T11:46:57.796945Z",
     "shell.execute_reply.started": "2025-03-12T11:46:18.712189Z",
     "shell.execute_reply": "2025-03-12T11:46:57.796083Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "torch\nX:    torch.Size([202033, 112])\ny:    torch.Size([202033])\n  fold 1\n    epoch    998: fold=0.4324 oof=0.4462\n    epoch    999: fold=0.4324 oof=0.4462\n    epoch   1000: fold=0.4324 oof=0.4462\n| ID | GPU | MEM |\n------------------\n|  0 | 87% |  4% |\n|  1 |  0% |  0% |\n\n  fold 2\n    epoch    998: fold=0.4340 oof=0.4400\n    epoch    999: fold=0.4340 oof=0.4400\n    epoch   1000: fold=0.4340 oof=0.4400\n| ID | GPU | MEM |\n------------------\n|  0 | 88% |  4% |\n|  1 |  0% |  0% |\n\n  fold 3\n    epoch    998: fold=0.4330 oof=0.4436\n    epoch    999: fold=0.4330 oof=0.4436\n    epoch   1000: fold=0.4330 oof=0.4436\n| ID | GPU | MEM |\n------------------\n|  0 | 88% |  4% |\n|  1 |  0% |  0% |\n\n  fold 4\n    epoch    998: fold=0.4325 oof=0.4433\n    epoch    999: fold=0.4325 oof=0.4433\n    epoch   1000: fold=0.4325 oof=0.4433\n| ID | GPU | MEM |\n------------------\n|  0 | 89% |  4% |\n|  1 |  0% |  0% |\n\n  fold 5\n    epoch    998: fold=0.4315 oof=0.4420\n    epoch    999: fold=0.4315 oof=0.4419\n    epoch   1000: fold=0.4315 oof=0.4419\n| ID | GPU | MEM |\n------------------\n|  0 | 89% |  4% |\n|  1 |  0% |  0% |\n\ntorch score:   0.1648\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 76
  },
  {
   "id": "acbfbae6-3f38-4071-8bd4-d3df13053067",
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}