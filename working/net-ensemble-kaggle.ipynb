{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11000041,"sourceType":"datasetVersion","datasetId":6847599}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"7c831638-c357-474c-9913-326593f9d1d9","cell_type":"code","source":"import warnings\n\nwarnings.simplefilter(\"ignore\")\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport torch\nimport torch.nn.functional as F\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import KFold\nimport cudf\n\nif torch.cuda.is_available():\n    device = \"cuda\"\nelse:\n    raise\n\nkfold = KFold(shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2025-03-12T02:34:04.790182Z","iopub.execute_input":"2025-03-12T02:34:04.790885Z","iopub.status.idle":"2025-03-12T02:34:04.796596Z","shell.execute_reply.started":"2025-03-12T02:34:04.790855Z","shell.execute_reply":"2025-03-12T02:34:04.795704Z"},"trusted":true},"outputs":[],"execution_count":13},{"id":"33aa42d7-39e8-43f8-9a3f-e46157420e4b","cell_type":"code","source":"fn = \"train_poss.csv\"\nprint(f\"reading {fn}\")\ntrain = pd.read_csv(f\"../input/net-dataset/{fn}\")\n\ntrain = pd.concat(\n    [\n        train.select_dtypes(\"int64\").astype(\"int32\"),\n        train.select_dtypes(\"float64\").astype(\"float32\"),\n    ],\n    axis=1,\n)\n\nprint(f\"\\ntrain: {str(train.shape):>23}\")\nprint(f\"{train.columns.to_list()}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-12T02:34:04.797539Z","iopub.execute_input":"2025-03-12T02:34:04.797835Z","iopub.status.idle":"2025-03-12T02:34:08.852931Z","shell.execute_reply.started":"2025-03-12T02:34:04.797803Z","shell.execute_reply":"2025-03-12T02:34:08.851858Z"},"trusted":true},"outputs":[{"name":"stdout","text":"reading train_poss.csv\n\ntrain:           (202033, 117)\n['Season', 'DayNum', 'TeamID_1', 'TeamID_2', 'Margin', 'Score_poss_o_1', 'FGM_poss_o_1', 'FGA_poss_o_1', 'FGM3_poss_o_1', 'FGA3_poss_o_1', 'FTM_poss_o_1', 'FTA_poss_o_1', 'OR_poss_o_1', 'DR_poss_o_1', 'Ast_poss_o_1', 'TO_poss_o_1', 'Stl_poss_o_1', 'Blk_poss_o_1', 'PF_poss_o_1', 'Score_poss_d_1', 'FGM_poss_d_1', 'FGA_poss_d_1', 'FGM3_poss_d_1', 'FGA3_poss_d_1', 'FTM_poss_d_1', 'FTA_poss_d_1', 'OR_poss_d_1', 'DR_poss_d_1', 'Ast_poss_d_1', 'TO_poss_d_1', 'Stl_poss_d_1', 'Blk_poss_d_1', 'PF_poss_d_1', 'sos_Score_poss_o_1', 'sos_FGM_poss_o_1', 'sos_FGA_poss_o_1', 'sos_FGM3_poss_o_1', 'sos_FGA3_poss_o_1', 'sos_FTM_poss_o_1', 'sos_FTA_poss_o_1', 'sos_OR_poss_o_1', 'sos_DR_poss_o_1', 'sos_Ast_poss_o_1', 'sos_TO_poss_o_1', 'sos_Stl_poss_o_1', 'sos_Blk_poss_o_1', 'sos_PF_poss_o_1', 'sos_Score_poss_d_1', 'sos_FGM_poss_d_1', 'sos_FGA_poss_d_1', 'sos_FGM3_poss_d_1', 'sos_FGA3_poss_d_1', 'sos_FTM_poss_d_1', 'sos_FTA_poss_d_1', 'sos_OR_poss_d_1', 'sos_DR_poss_d_1', 'sos_Ast_poss_d_1', 'sos_TO_poss_d_1', 'sos_Stl_poss_d_1', 'sos_Blk_poss_d_1', 'sos_PF_poss_d_1', 'Score_poss_o_2', 'FGM_poss_o_2', 'FGA_poss_o_2', 'FGM3_poss_o_2', 'FGA3_poss_o_2', 'FTM_poss_o_2', 'FTA_poss_o_2', 'OR_poss_o_2', 'DR_poss_o_2', 'Ast_poss_o_2', 'TO_poss_o_2', 'Stl_poss_o_2', 'Blk_poss_o_2', 'PF_poss_o_2', 'Score_poss_d_2', 'FGM_poss_d_2', 'FGA_poss_d_2', 'FGM3_poss_d_2', 'FGA3_poss_d_2', 'FTM_poss_d_2', 'FTA_poss_d_2', 'OR_poss_d_2', 'DR_poss_d_2', 'Ast_poss_d_2', 'TO_poss_d_2', 'Stl_poss_d_2', 'Blk_poss_d_2', 'PF_poss_d_2', 'sos_Score_poss_o_2', 'sos_FGM_poss_o_2', 'sos_FGA_poss_o_2', 'sos_FGM3_poss_o_2', 'sos_FGA3_poss_o_2', 'sos_FTM_poss_o_2', 'sos_FTA_poss_o_2', 'sos_OR_poss_o_2', 'sos_DR_poss_o_2', 'sos_Ast_poss_o_2', 'sos_TO_poss_o_2', 'sos_Stl_poss_o_2', 'sos_Blk_poss_o_2', 'sos_PF_poss_o_2', 'sos_Score_poss_d_2', 'sos_FGM_poss_d_2', 'sos_FGA_poss_d_2', 'sos_FGM3_poss_d_2', 'sos_FGA3_poss_d_2', 'sos_FTM_poss_d_2', 'sos_FTA_poss_d_2', 'sos_OR_poss_d_2', 'sos_DR_poss_d_2', 'sos_Ast_poss_d_2', 'sos_TO_poss_d_2', 'sos_Stl_poss_d_2', 'sos_Blk_poss_d_2', 'sos_PF_poss_d_2']\n","output_type":"stream"}],"execution_count":14},{"id":"d2927d4b-8b36-4c2b-a795-25cf31f89f93","cell_type":"code","source":"X_df = train.drop(columns=[\"Season\", \"DayNum\", \"TeamID_1\", \"TeamID_2\", \"Margin\"])\nprint(f\"X_df: {str(X_df.shape):>24}\")\n\nX = torch.as_tensor(\n    StandardScaler().fit_transform(X_df.values),\n    dtype=torch.float32,\n    device=device,\n)\n\nprint(f\"X:    {X.shape}\")\n\ny_s = train[\"Margin\"]\nprint(f\"y_s: {str(y_s.shape):>21}\")\nscaler_y = StandardScaler()\n\ny = torch.tensor(\n    scaler_y.fit_transform(train[[\"Margin\"]]).flatten(),\n    dtype=torch.float32,\n    device=device,\n)\n\nprint(f\"y:    {y.shape}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-12T02:34:08.854957Z","iopub.execute_input":"2025-03-12T02:34:08.855214Z","iopub.status.idle":"2025-03-12T02:34:09.278578Z","shell.execute_reply.started":"2025-03-12T02:34:08.855193Z","shell.execute_reply":"2025-03-12T02:34:09.277683Z"},"trusted":true},"outputs":[{"name":"stdout","text":"X_df:            (202033, 112)\nX:    torch.Size([202033, 112])\ny_s:             (202033,)\ny:    torch.Size([202033])\n","output_type":"stream"}],"execution_count":15},{"id":"a4b9f99f-7e01-41e1-b8d8-94be5d26efa1","cell_type":"code","source":"def brier_score(y_pred_np, y_true_s):\n    pred_win_prob = 1 / (1 + np.exp(-y_pred_np * 0.1))\n    team_1_won = (y_true_s.values > 0).astype(float)\n    return np.mean((pred_win_prob - team_1_won) ** 2)","metadata":{"execution":{"iopub.status.busy":"2025-03-12T02:34:09.279711Z","iopub.execute_input":"2025-03-12T02:34:09.279941Z","iopub.status.idle":"2025-03-12T02:34:09.284245Z","shell.execute_reply.started":"2025-03-12T02:34:09.279901Z","shell.execute_reply":"2025-03-12T02:34:09.283463Z"},"trusted":true},"outputs":[],"execution_count":16},{"id":"7742f9cc-5a0a-4cea-a06e-f12e18e03a32","cell_type":"code","source":"params = {\n    \"tree_method\": \"hist\",\n    \"device\": \"gpu\",\n    \"max_depth\": 3,\n    \"colsample_bytree\": 0.5,\n    \"subsample\": 0.8,\n    \"eta\": 0.02,\n    \"min_child_weight\": 80,\n    \"verbosity\": 1,\n}\n\nprint(f\"xgboost\")\ny_pred_oof = np.zeros(y_s.shape[0])\ny_pred_oof2 = np.zeros(y_s.shape[0])\n    \nfor fold_n, (i_fold, i_oof) in enumerate(kfold.split(X_df.index), 1):\n    print(f\"  fold {fold_n}\")\n    dm_fold = xgb.DMatrix(X_df.iloc[i_fold], label=y_s.iloc[i_fold])\n    dm_oof = xgb.DMatrix(X_df.iloc[i_oof], label=y_s.iloc[i_oof])\n\n    print(\"  xgb.train\")\n    m = xgb.train(\n        params,\n        dm_fold,\n        num_boost_round=2000,\n        evals=[(dm_fold, \"fold\"), (dm_oof, \"oof\")],\n        verbose_eval=250,\n    )\n\n    y_pred_oof[i_oof] = m.predict(dm_oof)\n    \n    print(\"  XGBRegressor\")\n    m = xgb.XGBRegressor(\n        tree_method=\"hist\",\n        device=\"cuda\",\n        max_depth=3,\n        colsample_bytree=0.5,\n        subsample=0.8,\n        n_estimators=2000,\n        learning_rate=0.02,\n        min_child_weight=80,\n        verbosity=1,\n    )\n    \n    X_fold = cudf.DataFrame.from_pandas(X_df.iloc[i_fold])\n    y_fold = cudf.Series(y_s.iloc[i_fold])\n    X_oof = cudf.DataFrame.from_pandas(X_df.iloc[i_oof])\n    y_oof = cudf.Series(y_s.iloc[i_oof])\n    \n    m.fit(\n        X_fold,\n        y_fold,\n        verbose=250,\n        eval_set=[\n            (X_fold, y_fold),\n            (X_oof, y_oof)\n        ],\n    )\n    \n    y_pred_oof2[i_oof] = m.predict(X_oof)\n    \n    print()\n\nscore = brier_score(y_pred_oof, y_s)\nprint(f\"  score: {score:.4f}\")\nscore = brier_score(y_pred_oof2, y_s)\nprint(f\"  score: {score:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-12T02:34:09.285103Z","iopub.execute_input":"2025-03-12T02:34:09.285382Z","iopub.status.idle":"2025-03-12T02:35:57.771299Z","shell.execute_reply.started":"2025-03-12T02:34:09.285360Z","shell.execute_reply":"2025-03-12T02:35:57.770115Z"},"trusted":true},"outputs":[{"name":"stdout","text":"xgboost\n  fold 1\n  xgb.train\n[0]\tfold-rmse:16.41412\toof-rmse:16.49274\n[250]\tfold-rmse:11.81616\toof-rmse:11.91527\n[500]\tfold-rmse:11.23284\toof-rmse:11.35894\n[750]\tfold-rmse:11.05311\toof-rmse:11.20042\n[1000]\tfold-rmse:10.97224\toof-rmse:11.13901\n[1250]\tfold-rmse:10.92507\toof-rmse:11.10907\n[1500]\tfold-rmse:10.89068\toof-rmse:11.09109\n[1750]\tfold-rmse:10.86242\toof-rmse:11.07966\n[1999]\tfold-rmse:10.83845\toof-rmse:11.07211\n  XGBRegressor\n[0]\tvalidation_0-rmse:16.41412\tvalidation_1-rmse:16.49274\n[250]\tvalidation_0-rmse:11.81616\tvalidation_1-rmse:11.91527\n[500]\tvalidation_0-rmse:11.23284\tvalidation_1-rmse:11.35894\n[750]\tvalidation_0-rmse:11.05311\tvalidation_1-rmse:11.20042\n[1000]\tvalidation_0-rmse:10.97224\tvalidation_1-rmse:11.13901\n[1250]\tvalidation_0-rmse:10.92507\tvalidation_1-rmse:11.10907\n[1500]\tvalidation_0-rmse:10.89068\tvalidation_1-rmse:11.09109\n[1750]\tvalidation_0-rmse:10.86242\tvalidation_1-rmse:11.07966\n[1999]\tvalidation_0-rmse:10.83845\tvalidation_1-rmse:11.07211\n\n  fold 2\n  xgb.train\n[0]\tfold-rmse:16.41678\toof-rmse:16.44453\n[250]\tfold-rmse:11.82918\toof-rmse:11.83978\n[500]\tfold-rmse:11.24746\toof-rmse:11.27648\n[750]\tfold-rmse:11.06912\toof-rmse:11.11724\n[1000]\tfold-rmse:10.99009\toof-rmse:11.05728\n[1250]\tfold-rmse:10.94168\toof-rmse:11.02836\n[1500]\tfold-rmse:10.90663\toof-rmse:11.01255\n[1750]\tfold-rmse:10.87854\toof-rmse:11.00239\n[1999]\tfold-rmse:10.85455\toof-rmse:10.99577\n  XGBRegressor\n[0]\tvalidation_0-rmse:16.41678\tvalidation_1-rmse:16.44453\n[250]\tvalidation_0-rmse:11.82918\tvalidation_1-rmse:11.83978\n[500]\tvalidation_0-rmse:11.24746\tvalidation_1-rmse:11.27648\n[750]\tvalidation_0-rmse:11.06912\tvalidation_1-rmse:11.11724\n[1000]\tvalidation_0-rmse:10.99009\tvalidation_1-rmse:11.05728\n[1250]\tvalidation_0-rmse:10.94168\tvalidation_1-rmse:11.02836\n[1500]\tvalidation_0-rmse:10.90663\tvalidation_1-rmse:11.01255\n[1750]\tvalidation_0-rmse:10.87854\tvalidation_1-rmse:11.00239\n[1999]\tvalidation_0-rmse:10.85455\tvalidation_1-rmse:10.99577\n\n  fold 3\n  xgb.train\n[0]\tfold-rmse:16.43755\toof-rmse:16.40973\n[250]\tfold-rmse:11.81925\toof-rmse:11.91708\n[500]\tfold-rmse:11.23273\toof-rmse:11.34793\n[750]\tfold-rmse:11.05455\toof-rmse:11.18916\n[1000]\tfold-rmse:10.97384\toof-rmse:11.12728\n[1250]\tfold-rmse:10.92673\toof-rmse:11.09887\n[1500]\tfold-rmse:10.89302\toof-rmse:11.08192\n[1750]\tfold-rmse:10.86512\toof-rmse:11.07105\n[1999]\tfold-rmse:10.84202\toof-rmse:11.06395\n  XGBRegressor\n[0]\tvalidation_0-rmse:16.43755\tvalidation_1-rmse:16.40973\n[250]\tvalidation_0-rmse:11.81925\tvalidation_1-rmse:11.91708\n[500]\tvalidation_0-rmse:11.23273\tvalidation_1-rmse:11.34793\n[750]\tvalidation_0-rmse:11.05455\tvalidation_1-rmse:11.18916\n[1000]\tvalidation_0-rmse:10.97384\tvalidation_1-rmse:11.12728\n[1250]\tvalidation_0-rmse:10.92673\tvalidation_1-rmse:11.09887\n[1500]\tvalidation_0-rmse:10.89302\tvalidation_1-rmse:11.08192\n[1750]\tvalidation_0-rmse:10.86512\tvalidation_1-rmse:11.07105\n[1999]\tvalidation_0-rmse:10.84202\tvalidation_1-rmse:11.06395\n\n  fold 4\n  xgb.train\n[0]\tfold-rmse:16.44885\toof-rmse:16.36198\n[250]\tfold-rmse:11.82601\toof-rmse:11.84448\n[500]\tfold-rmse:11.24018\toof-rmse:11.31309\n[750]\tfold-rmse:11.06067\toof-rmse:11.16409\n[1000]\tfold-rmse:10.98027\toof-rmse:11.10693\n[1250]\tfold-rmse:10.93366\toof-rmse:11.07866\n[1500]\tfold-rmse:10.89967\toof-rmse:11.06103\n[1750]\tfold-rmse:10.87201\toof-rmse:11.04947\n[1999]\tfold-rmse:10.84942\toof-rmse:11.04161\n  XGBRegressor\n[0]\tvalidation_0-rmse:16.44885\tvalidation_1-rmse:16.36198\n[250]\tvalidation_0-rmse:11.82601\tvalidation_1-rmse:11.84448\n[500]\tvalidation_0-rmse:11.24018\tvalidation_1-rmse:11.31309\n[750]\tvalidation_0-rmse:11.06067\tvalidation_1-rmse:11.16409\n[1000]\tvalidation_0-rmse:10.98027\tvalidation_1-rmse:11.10693\n[1250]\tvalidation_0-rmse:10.93366\tvalidation_1-rmse:11.07866\n[1500]\tvalidation_0-rmse:10.89967\tvalidation_1-rmse:11.06103\n[1750]\tvalidation_0-rmse:10.87201\tvalidation_1-rmse:11.04947\n[1999]\tvalidation_0-rmse:10.84942\tvalidation_1-rmse:11.04161\n\n  fold 5\n  xgb.train\n[0]\tfold-rmse:16.42735\toof-rmse:16.43855\n[250]\tfold-rmse:11.83235\toof-rmse:11.88605\n[500]\tfold-rmse:11.24305\toof-rmse:11.32131\n[750]\tfold-rmse:11.06342\toof-rmse:11.16125\n[1000]\tfold-rmse:10.98315\toof-rmse:11.09827\n[1250]\tfold-rmse:10.93662\toof-rmse:11.06861\n[1500]\tfold-rmse:10.90162\toof-rmse:11.05145\n[1750]\tfold-rmse:10.87281\toof-rmse:11.04075\n[1999]\tfold-rmse:10.84913\toof-rmse:11.03351\n  XGBRegressor\n[0]\tvalidation_0-rmse:16.42735\tvalidation_1-rmse:16.43855\n[250]\tvalidation_0-rmse:11.83235\tvalidation_1-rmse:11.88605\n[500]\tvalidation_0-rmse:11.24305\tvalidation_1-rmse:11.32131\n[750]\tvalidation_0-rmse:11.06342\tvalidation_1-rmse:11.16125\n[1000]\tvalidation_0-rmse:10.98315\tvalidation_1-rmse:11.09827\n[1250]\tvalidation_0-rmse:10.93662\tvalidation_1-rmse:11.06861\n[1500]\tvalidation_0-rmse:10.90162\tvalidation_1-rmse:11.05145\n[1750]\tvalidation_0-rmse:10.87281\tvalidation_1-rmse:11.04075\n[1999]\tvalidation_0-rmse:10.84913\tvalidation_1-rmse:11.03351\n\n  score: 0.1660\n  score: 0.1660\n","output_type":"stream"}],"execution_count":17},{"id":"5da53c98-c616-4e83-9e0d-0d732e0eeb59","cell_type":"code","source":"print(\"torch\")\nn_epochs = 1_000\nhidden_size = 64\nloss_fn = torch.nn.MSELoss()\n\ny_pred_oof = torch.zeros(\n    y.shape[0],\n    dtype=torch.float32,\n    requires_grad=False,\n    device=device,\n)\n\nfor fold_n, (i_fold, i_oof) in enumerate(kfold.split(X_df.index), 1):\n    print(f\"  fold {fold_n}\")\n\n    weights1 = torch.nn.Parameter(\n        0.1 * torch.randn(X_df.shape[1], hidden_size, device=device)\n    )\n    bias1 = torch.nn.Parameter(torch.zeros(hidden_size, device=device))\n    weights2 = torch.nn.Parameter(0.1 * torch.randn(hidden_size, 1, device=device))\n    bias2 = torch.nn.Parameter(torch.zeros(1, device=device))\n    optimizer = torch.optim.Adam([weights1, bias1, weights2, bias2], weight_decay=1e-4)\n\n    for epoch_n in range(1, n_epochs + 1):\n        y_pred_fold_epoch = F.leaky_relu(X[i_fold] @ weights1 + bias1, negative_slope=0.1) @ weights2 + bias2\n        loss_fold_epoch = loss_fn(y_pred_fold_epoch, y[i_fold].view(-1, 1))\n        optimizer.zero_grad()\n        loss_fold_epoch.backward()\n        optimizer.step()\n\n        with torch.no_grad():\n            y_pred_oof_epoch = F.leaky_relu(X[i_oof] @ weights1 + bias1, negative_slope=0.1) @ weights2 + bias2\n            loss_oof_epoch = loss_fn(y_pred_oof_epoch, y[i_oof].view(-1, 1))\n\n        if epoch_n > (n_epochs - 3):\n            print(\n                f\"    epoch {epoch_n:>6}: \"\n                f\"fold={loss_fold_epoch.item():.4f} \"\n                f\"oof={loss_oof_epoch.item():.4f}\"\n            )\n\n    with torch.no_grad():\n        y_pred_oof[i_oof] = (\n            F.leaky_relu(X[i_oof] @ weights1 + bias1, negative_slope=0.1) @ weights2 + bias2\n        ).flatten()\n\n    print()\n\ny_pred_oof = scaler_y.inverse_transform(\n    y_pred_oof.cpu().numpy().reshape(-1, 1)\n).flatten()\n\nscore = brier_score(y_pred_oof, y_s)\nprint(f\"  score: {score:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2025-03-12T02:35:57.772380Z","iopub.execute_input":"2025-03-12T02:35:57.772734Z","iopub.status.idle":"2025-03-12T02:36:34.919757Z","shell.execute_reply.started":"2025-03-12T02:35:57.772698Z","shell.execute_reply":"2025-03-12T02:36:34.918793Z"},"trusted":true},"outputs":[{"name":"stdout","text":"torch\n  fold 1\n    epoch    998: fold=0.4326 oof=0.4466\n    epoch    999: fold=0.4326 oof=0.4466\n    epoch   1000: fold=0.4326 oof=0.4466\n\n  fold 2\n    epoch    998: fold=0.4357 oof=0.4407\n    epoch    999: fold=0.4357 oof=0.4407\n    epoch   1000: fold=0.4357 oof=0.4407\n\n  fold 3\n    epoch    998: fold=0.4333 oof=0.4437\n    epoch    999: fold=0.4333 oof=0.4438\n    epoch   1000: fold=0.4333 oof=0.4437\n\n  fold 4\n    epoch    998: fold=0.4329 oof=0.4422\n    epoch    999: fold=0.4329 oof=0.4422\n    epoch   1000: fold=0.4328 oof=0.4422\n\n  fold 5\n    epoch    998: fold=0.4328 oof=0.4433\n    epoch    999: fold=0.4328 oof=0.4434\n    epoch   1000: fold=0.4328 oof=0.4433\n\n  score: 0.1649\n","output_type":"stream"}],"execution_count":18},{"id":"b0b4b5b9-c1f0-4eae-81ca-ef7cff7a953e","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}